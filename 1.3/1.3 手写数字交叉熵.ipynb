{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7ff0af7771d0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7ff0b466d898>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7ff0b466d6a0>)\n",
      "Tensor(\"Placeholder_59:0\", shape=(?, 784), dtype=float32)\n",
      "<tf.Variable 'Variable_64:0' shape=(784, 2000) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_65:0' shape=(2000,) dtype=float32_ref>\n",
      "L1=\n",
      "222\n",
      "Iter0 testacc0.9287trainacc0.937\n",
      "Iter1 testacc0.9495trainacc0.96549094\n",
      "Iter2 testacc0.9546trainacc0.97481817\n",
      "Iter3 testacc0.958trainacc0.98016363\n",
      "Iter4 testacc0.9618trainacc0.9836\n",
      "Iter5 testacc0.9619trainacc0.98554546\n",
      "Iter6 testacc0.9623trainacc0.9869273\n",
      "Iter7 testacc0.9628trainacc0.988\n",
      "Iter8 testacc0.9624trainacc0.9888727\n",
      "Iter9 testacc0.963trainacc0.9897636\n",
      "Iter10 testacc0.9648trainacc0.9902545\n",
      "Iter11 testacc0.9653trainacc0.99076366\n",
      "Iter12 testacc0.9653trainacc0.9911636\n",
      "Iter13 testacc0.9653trainacc0.99163634\n",
      "Iter14 testacc0.9663trainacc0.9918727\n",
      "Iter15 testacc0.9657trainacc0.9921273\n",
      "Iter16 testacc0.9666trainacc0.9924\n",
      "Iter17 testacc0.9669trainacc0.99265456\n",
      "Iter18 testacc0.9667trainacc0.99285454\n",
      "Iter19 testacc0.9665trainacc0.99314547\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#手写数字识别\n",
    "minst = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "print(minst)\n",
    "#定义每个批次的大小\n",
    "batch_size = 100\n",
    "\n",
    "#一共有多少个批次\n",
    "n_batch = minst.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None,10])\n",
    "keep_prob = tf.placeholder(tf.float32) #\n",
    "\n",
    "\n",
    "#创建一个神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 2000], stddev=0.1))\n",
    "print(x)\n",
    "print(W1)\n",
    "b1 = tf.Variable(tf.zeros([2000]) + 0.1)\n",
    "print(b1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "print('L1='%L1)\n",
    "#工作的神经元比例\n",
    "L1_drop = tf.nn.dropout(L1, keep_prob) \n",
    "\n",
    "#第二层网络\n",
    "W2 = tf.Variable(tf.truncated_normal([2000, 2000], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([2000]) + 0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop, W2) + b2)\n",
    "L2_drop = tf.nn.dropout(L2, keep_prob) \n",
    "\n",
    "#第三层网络\n",
    "W3 = tf.Variable(tf.truncated_normal([2000, 1000], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([1000]) + 0.1)\n",
    "L3= tf.nn.tanh(tf.matmul(L2_drop, W3) + b3)\n",
    "L3_drop = tf.nn.dropout(L3, keep_prob) \n",
    "\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([1000, 10], stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop, W4) + b4)\n",
    "\n",
    "\n",
    "#交叉熵\n",
    "# loss = tf.reduce_mean(tf.square(prediction - y))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "print(222)\n",
    "#将预测结果存在一个表中\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for iter in range(20):\n",
    "        for batch in range(n_batch):\n",
    "            batch_x, batch_y = minst.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_x, y:batch_y, keep_prob:1.0})  \n",
    "        testacc = sess.run(accuracy, feed_dict={x:minst.test.images, y:minst.test.labels,keep_prob:1.0})\n",
    "        trainacc = sess.run(accuracy, feed_dict={x:minst.train.images, y:minst.train.labels,keep_prob:1.0})\n",
    "        print(\"Iter\" + str(iter) + \" testacc\" + str(testacc) + \"trainacc\" + str(trainacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“3.6.7”",
   "language": "python",
   "name": "python3.6.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
